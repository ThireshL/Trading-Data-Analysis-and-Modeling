{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34734875",
   "metadata": {},
   "source": [
    "# Data analytics of EXI Dataset\n",
    "\n",
    "- Data collected from https://european-investor-exchange.com/en/trade-list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266af16",
   "metadata": {},
   "source": [
    "## Step 0 - Familiarisation with data\n",
    "- read csv files of october\n",
    "- basis statistics\n",
    "- descriptive statistics\n",
    "- basic visuals\n",
    "\n",
    "## Step 1 - Data Cleaning\n",
    "- Check and summarize missing values per column using combined_df.isnull().sum().\n",
    "- Drop duplicates with combined_df.drop_duplicates(inplace=True).\n",
    "- Convert data types:\n",
    "- Ensure Quantity and Unit Price are numeric.\n",
    "- Convert Trading day & Trading time UTC to datetime.\n",
    "- Standardize text-based columns such as Side and Price Currency by stripping spaces and converting to uppercase.\n",
    "\n",
    "## Step 2 - Feature Engineering\n",
    "- Add a new column: Trade Amount = Quantity × Unit Price.\n",
    "- Extract datetime features: date, time, hour, day of week.\n",
    "- Create log-transformed or normalized columns for skewed variables if relevant to modeling or visualization.\n",
    "\n",
    "## Step 3 - Exploratory Data Analysis (EDA)\n",
    "- Plot data distributions for Unit Price, Quantity, and Trade Amount.\n",
    "- Explore relationships like Quantity vs Unit Price and Trade Amount vs Side.\n",
    "- Identify time-based trading patterns — daily or hourly volumes and price trends.\n",
    "- Analyze top instruments and venues by total trade quantity or value.\n",
    "\n",
    "## Step 4 - Outlier Detection\n",
    "- Use boxplots or z-score thresholds to highlight outliers in Quantity and Unit Price.\n",
    "- Optionally apply the interquartile range (IQR) method to filter extreme values.\n",
    "- Visualize outlier patterns across Side or Venue Identifier.\n",
    "\n",
    "## Step 5 - Venue & Instrument Analysis\n",
    "- Aggregate by Venue Identifier and Instrument Identifier to observe trading concentration.\n",
    "- Identify instruments or venues with the highest variance in price or volume.\n",
    "- Visualize via bar charts or pie charts the proportion of trading volume by venue/instrument.\n",
    "\n",
    "## Step 6 - Model Preparation\n",
    "- Select relevant features — numeric variables (e.g., Trade Amount, Quantity) and categorical ones (Side, Venue Identifier).\n",
    "- Encode categorical variables using one-hot encoding.\n",
    "- Address data imbalance or skew using sampling or scaling.\n",
    "- Split into training and testing sets for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa13a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basis libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files in current directory\n",
    "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81edc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read single file to see the schema of the csv file\n",
    "df = pd.read_csv('Official_Trade_List_2025-10-01.csv')\n",
    "\n",
    "# View the first five rows\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files in the current directory\n",
    "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "\n",
    "# Read and combine them into one DataFrame\n",
    "if csv_files:  # Check if any CSV files exist\n",
    "    combined_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "    print(\"Combined DataFrame shape:\", combined_df.shape)\n",
    "else:\n",
    "    print(\"No CSV files found in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e7e31",
   "metadata": {},
   "source": [
    "# Basis Overview\n",
    "- data types\n",
    "- numerical distributions\n",
    "- missing values.\n",
    "- trade price ranges\n",
    "- the most frequently traded instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19fffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e806b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf47635",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "-  trade price ranges\n",
    "- the most frequently traded instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bf35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.groupby('Side')['Unit Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df['Instrument Identifier'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48365a",
   "metadata": {},
   "source": [
    "### Key Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2143e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=combined_df, x='Side')\n",
    "plt.title('Distribution of Trade Sides')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=combined_df, x='Unit Price', bins=50, kde=True)\n",
    "plt.title('Distribution of Unit Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82058b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=combined_df, x='Side', y='Unit Price')\n",
    "plt.title('Unit Price by Trade Side')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f422cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=combined_df, x='Quantity', y='Unit Price', hue='Side', alpha=0.6)\n",
    "plt.title('Quantity vs Unit Price by Side')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ddbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Trading day & Trading time UTC'] = pd.to_datetime(combined_df['Trading day & Trading time UTC'])\n",
    "daily_volume = combined_df.groupby(combined_df['Trading day & Trading time UTC'].dt.date)['Quantity'].sum()\n",
    "\n",
    "daily_volume.plot(kind='line', figsize=(12,5), title='Daily Trade Volume Over Time')\n",
    "plt.ylabel('Total Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c5881",
   "metadata": {},
   "source": [
    "## Step-1 Data Cleaning\n",
    "How this helps:\n",
    "\n",
    "- Converts all types correctly for quantitative and time-series analysis.\n",
    "- Normalizes categorical text fields.\n",
    "- Eliminates duplicates and reveals missing data accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check and summarize missing values per column\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# 2. Drop duplicate rows\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 3. Convert data types\n",
    "combined_df['Trading day & Trading time UTC'] = pd.to_datetime(combined_df['Trading day & Trading time UTC'], errors='coerce')\n",
    "combined_df['Quantity'] = pd.to_numeric(combined_df['Quantity'], errors='coerce')\n",
    "combined_df['Unit Price'] = pd.to_numeric(combined_df['Unit Price'], errors='coerce')\n",
    "\n",
    "# 4. Standardize text-based columns\n",
    "combined_df['Side'] = combined_df['Side'].str.strip().str.upper()\n",
    "combined_df['Price Currency'] = combined_df['Price Currency'].str.strip().str.upper()\n",
    "\n",
    "# 5. Summary after cleaning\n",
    "print('Shape after cleaning:', combined_df.shape)\n",
    "print('Remaining null values:', combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13eb02",
   "metadata": {},
   "source": [
    "## Step-2 Feature Engineering\n",
    "\n",
    "- The new Trade Amount column captures trade value and will be key in later analyses.\n",
    "- Extracted date/time fields allow temporal pattern detection (hourly, daily, weekday trends).\n",
    "- Log-transformed features help stabilize variance in price and quantity during visualization and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create new derived column: Trade Amount (Quantity × Unit Price)\n",
    "combined_df['Trade Amount'] = combined_df['Quantity'] * combined_df['Unit Price']\n",
    "\n",
    "# 2. Extract datetime components for time-based analysis\n",
    "combined_df['Trade Date'] = combined_df['Trading day & Trading time UTC'].dt.date\n",
    "combined_df['Trade Hour'] = combined_df['Trading day & Trading time UTC'].dt.hour\n",
    "combined_df['Trade Weekday'] = combined_df['Trading day & Trading time UTC'].dt.day_name()\n",
    "combined_df['Trade Month'] = combined_df['Trading day & Trading time UTC'].dt.month\n",
    "\n",
    "# 3. (Optional) Log-transform skewed numeric features for better visualization later\n",
    "import numpy as np\n",
    "for col in ['Quantity', 'Unit Price', 'Trade Amount']:\n",
    "    combined_df[f'log_{col}'] = np.log1p(combined_df[col])\n",
    "\n",
    "# 4. Quick verification summary\n",
    "print(combined_df[['Quantity', 'Unit Price', 'Trade Amount']].describe())\n",
    "print(combined_df[['Trade Date', 'Trade Hour', 'Trade Weekday', 'Trade Month']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73eaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422e13c",
   "metadata": {},
   "source": [
    "## Step-3 EDA\n",
    "#### What this step reveals:\n",
    "\n",
    "- Numerical summaries for trade prices, quantities, and total value.\n",
    "- Top traded instruments to identify liquidity concentration.\n",
    "- Side distribution (Buy/Sell ratio).\n",
    "- Temporal patterns — daily and hourly trading activity.\n",
    "- Relationships between trade quantity and unit price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b077b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Statistical summaries\n",
    "print(\"\\n[INFO] Descriptive summary of key numeric columns:\")\n",
    "print(combined_df[['Quantity', 'Unit Price', 'Trade Amount']].describe())\n",
    "\n",
    "print(\"\\n[INFO] Top 10 most traded instruments by total quantity:\")\n",
    "print(combined_df.groupby('Instrument Identifier')['Quantity'].sum()\n",
    "      .sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n[INFO] Trade side distribution counts:\")\n",
    "print(combined_df['Side'].value_counts())\n",
    "\n",
    "# 2. Visualizations\n",
    "\n",
    "# Distribution of trade sides\n",
    "sns.countplot(data=combined_df, x='Side')\n",
    "plt.title('Distribution of Trade Sides')\n",
    "plt.xlabel('Trade Side')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of unit prices\n",
    "sns.histplot(data=combined_df, x='Unit Price', bins=50, kde=True)\n",
    "plt.title('Distribution of Unit Prices')\n",
    "plt.xlabel('Unit Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Quantity vs Unit Price by Side\n",
    "sns.scatterplot(data=combined_df, x='Quantity', y='Unit Price', hue='Side', alpha=0.5)\n",
    "plt.title('Quantity vs Unit Price by Trade Side')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Unit Price')\n",
    "plt.show()\n",
    "\n",
    "# Daily trade volume trends\n",
    "daily_volume = combined_df.groupby('Trade Date')['Quantity'].sum().reset_index()\n",
    "sns.lineplot(data=daily_volume, x='Trade Date', y='Quantity')\n",
    "plt.title('Daily Trade Volume Over Time')\n",
    "plt.xlabel('Trade Date')\n",
    "plt.ylabel('Total Quantity')\n",
    "plt.show()\n",
    "\n",
    "# Hourly trade activity trends\n",
    "hourly_volume = combined_df.groupby('Trade Hour')['Quantity'].sum().reset_index()\n",
    "sns.barplot(data=hourly_volume, x='Trade Hour', y='Quantity', palette='viridis')\n",
    "plt.title('Trading Activity by Hour of Day')\n",
    "plt.xlabel('Hour (UTC)')\n",
    "plt.ylabel('Total Quantity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db30b90",
   "metadata": {},
   "source": [
    "## Step-4: OutliersDetection\n",
    "- Boxplots quickly highlight extreme outliers visually.\n",
    "- The IQR method identifies and removes statistically extreme points while preserving most of the valid observations.\n",
    "- Comparing statistics before and after filtering quantifies the effect of outlier handling on Quantity and Unit Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215ce7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6841663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visual examination of outliers using boxplots\n",
    "print(\"\\n[INFO] Visualizing Unit Price outliers using boxplot:\")\n",
    "sns.boxplot(data=combined_df, x='Unit Price')\n",
    "plt.title('Unit Price Outlier Detection (Boxplot)')\n",
    "plt.xlabel('Unit Price')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[INFO] Visualizing Quantity outliers using boxplot:\")\n",
    "sns.boxplot(data=combined_df, x='Quantity')\n",
    "plt.title('Quantity Outlier Detection (Boxplot)')\n",
    "plt.xlabel('Quantity')\n",
    "plt.show()\n",
    "\n",
    "# 2. Statistical detection using the IQR method\n",
    "def detect_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "quantity_outliers = detect_outliers_iqr(combined_df['Quantity'])\n",
    "price_outliers = detect_outliers_iqr(combined_df['Unit Price'])\n",
    "\n",
    "print(f\"\\n[INFO] Number of Quantity outliers detected: {len(quantity_outliers)}\")\n",
    "print(f\"[INFO] Number of Unit Price outliers detected: {len(price_outliers)}\")\n",
    "\n",
    "# 3. Statistical comparison before and after filtering\n",
    "print(\"\\n[INFO] Summary statistics BEFORE filtering outliers:\")\n",
    "print(combined_df[['Quantity', 'Unit Price']].describe())\n",
    "\n",
    "# Optionally remove outliers for clean analysis\n",
    "cleaned_df = combined_df[~combined_df['Quantity'].isin(quantity_outliers)]\n",
    "cleaned_df = cleaned_df[~cleaned_df['Unit Price'].isin(price_outliers)]\n",
    "\n",
    "print(\"\\n[INFO] Summary statistics AFTER removing outliers:\")\n",
    "print(cleaned_df[['Quantity', 'Unit Price']].describe())\n",
    "print(f\"[INFO] New dataset shape after outlier removal: {cleaned_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fb1a5",
   "metadata": {},
   "source": [
    "## Step-5 Venue and instrument analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aggregated metrics per venue\n",
    "print(\"\\n[INFO] Calculating aggregated trading metrics per venue:\")\n",
    "venue_summary = cleaned_df.groupby('Venue Identifier').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'Trade Amount': 'sum',\n",
    "    'Instrument Identifier': 'nunique'\n",
    "}).sort_values(by='Trade Amount', ascending=False)\n",
    "\n",
    "print(\"\\n[INFO] Top 10 venues by total trade amount:\")\n",
    "print(venue_summary.head(10))\n",
    "\n",
    "# Visualize top trading venues\n",
    "sns.barplot(\n",
    "    data=venue_summary.head(10).reset_index(),\n",
    "    x='Venue Identifier',\n",
    "    y='Trade Amount',\n",
    "    palette='coolwarm'\n",
    ")\n",
    "plt.title('Top 10 Venues by Trade Amount')\n",
    "plt.xlabel('Venue Identifier')\n",
    "plt.ylabel('Total Trade Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 2. Instrument-level analysis\n",
    "print(\"\\n[INFO] Calculating key trade statistics per instrument:\")\n",
    "instrument_summary = cleaned_df.groupby('Instrument Identifier').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'Trade Amount': 'sum',\n",
    "    'Unit Price': 'mean',\n",
    "    'Venue Identifier': 'nunique'\n",
    "}).sort_values(by='Trade Amount', ascending=False)\n",
    "\n",
    "print(\"\\n[INFO] Top 10 instruments by total trade amount:\")\n",
    "print(instrument_summary.head(10))\n",
    "\n",
    "# Visualize instrument concentration\n",
    "sns.barplot(\n",
    "    data=instrument_summary.head(10).reset_index(),\n",
    "    x='Instrument Identifier',\n",
    "    y='Trade Amount',\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Top 10 Instruments by Trade Amount')\n",
    "plt.xlabel('Instrument Identifier')\n",
    "plt.ylabel('Total Trade Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Cross-analysis between Trade Side and Venue\n",
    "print(\"\\n[INFO] Analyzing trade side distributions per venue:\")\n",
    "side_venue = cleaned_df.groupby(['Venue Identifier', 'Side']).size().unstack(fill_value=0)\n",
    "print(side_venue.head())\n",
    "\n",
    "side_venue.plot(kind='bar', stacked=True, figsize=(10,6), colormap='coolwarm')\n",
    "plt.title('Trade Side Distribution per Venue')\n",
    "plt.xlabel('Venue Identifier')\n",
    "plt.ylabel('Trade Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46780503",
   "metadata": {},
   "source": [
    "## Step-7 Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c72aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Model Preparation ---\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Select relevant features for modeling\n",
    "print(\"\\n[INFO] Selecting relevant modeling features:\")\n",
    "selected_features = ['Quantity', 'Unit Price', 'Trade Amount', 'Price Currency', 'Venue Identifier', 'Side', 'Instrument Identifier']\n",
    "model_df = cleaned_df[selected_features].copy()\n",
    "print(model_df.head(5))\n",
    "\n",
    "# 2. One-hot encode categorical features\n",
    "print(\"\\n[INFO] Encoding categorical features:\")\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_features = pd.DataFrame(\n",
    "    ohe.fit_transform(model_df[['Price Currency', 'Venue Identifier', 'Side', 'Instrument Identifier']]),\n",
    "    columns=ohe.get_feature_names_out(['Price Currency', 'Venue Identifier', 'Side', 'Instrument Identifier'])\n",
    ")\n",
    "\n",
    "# Combine encoded and numeric columns\n",
    "model_ready_df = pd.concat([model_df[['Quantity', 'Unit Price', 'Trade Amount']].reset_index(drop=True), encoded_features], axis=1)\n",
    "\n",
    "print(f\"[INFO] Final shape after encoding: {model_ready_df.shape}\")\n",
    "print(\"[INFO] Displaying first 5 rows of model-ready dataset:\")\n",
    "print(model_ready_df.head())\n",
    "\n",
    "# 3. Split dataset for modeling\n",
    "print(\"\\n[INFO] Splitting data into training and testing sets:\")\n",
    "X = model_ready_df.drop('Trade Amount', axis=1)\n",
    "y = model_ready_df['Trade Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"[INFO] Training samples: {X_train.shape[0]}\")\n",
    "print(f\"[INFO] Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# 4. Scale numeric variables\n",
    "print(\"\\n[INFO] Scaling numeric features for model consistency:\")\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Quantity', 'Unit Price']\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"[INFO] Model preparation completed. Data is ready for machine learning or regression analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e66f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
